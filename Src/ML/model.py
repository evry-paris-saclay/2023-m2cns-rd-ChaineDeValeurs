# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kzX_UskUS9ViMf04-Tvhb0q7uATvN21I
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import os
import cv2
import numpy as np



from google.colab import drive
drive.mount('/content/drive')

# Charger les images et les étiquettes
data_dir = "/content/drive/MyDrive/MedicalWaste"
classes = os.listdir(data_dir)
images = []
labels = []

for i, classe in enumerate(classes):
    path = os.path.join(data_dir, classe)
    for img in os.listdir(path):
        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)
        img_array = cv2.resize(img_array, (100, 100))  # Ajustez la taille selon vos besoins
        images.append(img_array)
        labels.append(i)

# Convertir en tableau NumPy
images = np.array(images)
labels = np.array(labels)

# Normaliser les valeurs des pixels
images = images / 255.0

# Diviser les données en ensembles d'entraînement, de validation et de test
x_train, x_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)
x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

model = keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(len(classes), activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))

test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {test_acc}")

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()

predictions = model.predict(x_test)

# Sauvegarder le modèle
model.save("x_test.h5")


# Charger le modèle
model = load_model("x_test.h5")


# Charger une nouvelle image pour la prédiction
img_path = "/content/drive/MyDrive/images.jpg"
img = image.load_img(img_path, target_size=(100, 100))  # Redimensionnez selon vos besoins
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Ajoutez une dimension batch
img_array /= 255.0  # Normalisez les valeurs des pixels (selon votre prétraitement)

predictions = model.predict(img_array)

predicted_class_index = np.argmax(predictions)
predicted_class = classes[predicted_class_index]
print(f"La classe prédite est : {predicted_class}")